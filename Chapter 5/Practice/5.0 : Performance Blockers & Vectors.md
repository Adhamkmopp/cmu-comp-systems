"Determining which combinations of transformations to apply is indeed part of the "black art" of writing fast code."


## Optimization blockers:

Specifically for compilers, some code aspects block certain optimizations. These include:

I.  Memory aliases: if a compiler cannot determine whether or not pointers will be aliases/refer to the same location.
II. Function calls: repeated function calls are costly where a reduced number of  calls is not (bookkeeping: parameters, local variables, rbp and rsi are saved/set each time). A functional call may need repeated calls however, blocking inline substituion.


## Critical paths & Overhead: 

This deserves a section all by itself. Critical paths are chains of dependencies that slow down a program through repeated execution. This is only meaningful in the context of clock cycles spent per instruction, which in turn, is made clear after learning about the hardware of the cpu and what clocked registers and combinatorial circuits mean, and how they're updated. "Wasteful" time spent means that a clock cycle has been wasted, which generally means (aside from optimizing basic arithmetic functions) that a register was updated, or data was involved in a memory operation which otherwise could have been avoided. 


## Long example: Vectors

Below is the code for allocating a vector and two more functions for retrieving elements and lengths which will be used in the subsequent 5 refinements over a code that performs an arithmetic operation on all elements of the vector.

```c++

typedef long data_t;

    typedef struct{
        long len;
        data_t *data;
    } vec_rec, *vec_ptr;


vec_ptr new_vec(long len){
    /* Allocate header structure */
    vec_ptr result = (vec_ptr) malloc(sizeof(vec_rec));
    data_t *data=NULL;
    if (!result)
        return NULL;    /* Could not allocate storage */
    result ->len=len;
    if(len>0)
        data = (data_t*)calloc(len, sizeof(data_t));
        if(!data){
            free((void*) result);
            return NULL;    /* Could not allocate storage */
        }
        result ->data = data;
        return result; 
}

int get_vec_element (vec_ptr v, long index, data_t *dest){
    if (index < 0 || index >= v->len)
        return 0;
    *dest = v ->data[index];
    return 1;
}

long vec_length(vec_ptr v){
    return v -> len;
}
```

### Pure Form

The first iteration of a sigma operation is slow, because it calls vec_length repeatedly each iteration of the loop with all that entails (possibly storing rbp and updating rsp).

```c++

void combine1 (vec_ptr v, data_t *dest){
    long i;
    *dest = 0;
    for (i = 0; i <vec_length(v); i++){
        data_t val;
        get_vec_element (v, i , &val);
        *dest = *dest + val;
    }
}
```


### Reducing Function Calls

The second iteration is much faster by comparison as it eliminates repeated function calls to vec_length.

```c++

void combine2 (vec_ptr v, data_t *dest){
    long i;
    long length = vec_length(v);
    *dest = 0;
    for (i = 0; i <length; i++){
        data_t val;
        get_vec_element (v, i , &val);
        *dest = *dest + val;
    }
}
```

### Reducing Function Calls (Again)

The third iteration does away with function calls entirely by setting a pointer to the start of the vector and using pointer arithmetic to fetch the next element (a load operation running in parallel to the multiplication/addition operation every clock cycle).

```c++
data_t *get_vec_start(vec_ptr v){
    return v ->data;
}

void combine3 (vec_ptr v, data_t *dest){
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    
    *dest = 0;
    for (i = 0; i <length; i++){
        *dest = *dest + data[i];
    }
}
```

This should have theoretically led to much higher performance improvements, but it did not. There are other bottlenecks that are not yet apparent in code.

### Eliminating Memory References

The fourth iteration eliminates memory references by avoiding repeated calls to dereference *dest and storing the data in a seperate variable instead (to be stored in regsiter xmm0).
```c++
data_t *get_vec_start(vec_ptr v){
    return v ->data;
}

void combine4 (vec_ptr v, data_t *dest){
    long i;
    long length = vec_length(v);
    data_t *data = get_vec_start(v);
    data_t acc = 0;
    
    
    for (i = 0; i <length; i++){
        acc = acc + data[i];
    }
    *dest = acc;
}
```
```c++
data_t *get_vec_start(vec_ptr v){
    return v ->data;
}


### Reducing Overhead (Loop Unrolling)

Here, two or more elements are added at a time reducing overhead (which probably involves branch prediction and something else that happens within the loop aside from termination/initiation):

void combine5  (vec_ptr v, data_t *dest){

    long i;
    long length = vec_length(v);
    long limit = length -1;
    data_t *data = get_vec_start(v);
    data_t acc = 0;

    for (i = 0; i <limit; i+=2){
        acc = (acc + data[i]) + data[i+1];
    }

    for (; i < length; i++){
        acc = acc + data[i];
    }
    *dest=acc;
}

In terms of machine code, combine5 does a more direct memory reference:

i in %rdx
vmulsd  (%rax,%rdx,8), %xmm0, %xmm0
vmulsd  8(%rax,%rdx,8), %xmm0, %xmm0
addq    $2, %rdx

As opposed to combine4:

data[i] in %rdx
vmulsd  %rdx, %xmm0, %xmm0
addq $8, %rdx